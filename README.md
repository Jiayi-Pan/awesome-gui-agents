# üîÆ‚Üî üñ•Ô∏è/üì± Awesome GUI Agents ![Awesome](https://awesome.re/badge.svg)
A curated list of gui agents and resources

## Models (WIP)
| Name | Platform | Input | Paper | Release Date (Month/Year) |
| --- | --- | --- | --- | --- |
| AutoUI | Android | Image | [You Only Look at Screens: Multimodal Chain-of-Action Agents](https://arxiv.org/abs/2309.11436) | 9/23 |
| AutoDroid | Android | HTML | [Empowering LLM to use Smartphone for Intelligent Task Automation](https://arxiv.org/abs/2308.15272) | 8/23 |
| WebAgent | Web | HTML | [A Real-World WebAgent with Planning, Long Context Understanding, and Program Synthesis](https://arxiv.org/abs/2307.12856) | 7/23 |
| Mind2Web T5 Baseline | Web | HTML | [Mind2Web: Towards a Generalist Agent for the Web](https://arxiv.org/abs/2306.06070) | 6/23 |
| Mind2Web Prompt Baseline | Web | HTML | [Mind2Web: Towards a Generalist Agent for the Web](https://arxiv.org/abs/2306.06070) | 6/23 |
| ASH | Web | HTML | [Hierarchical Prompting Assists Large Language Model on Web Navigation](https://arxiv.org/abs/2305.14257) | 5/23 |
| Pix2Act | Web | Image | [From Pixels to UI Actions: Learning to Follow Instructions via Graphical User Interfaces](https://arxiv.org/abs/2306.00245) | 5/23 |
| WebGUM | Web | HTML, Image | [Multimodal Web Navigation with Instruction-Finetuned Foundation Models](https://arxiv.org/abs/2305.11854) | 5/23 |
| Humphreys et al, 22 | Web | HTML,Image | [A data-driven approach for learning to control computers](https://arxiv.org/abs/2202.08137) | 11/22 |
| MetaGUI Baseline | Android | XML, Image | [META-GUI: Towards Multi-modal Conversational Agents on Mobile GUI](https://arxiv.org/abs/2205.11029) | 11/22 |
| WebGPT | Web | Custom Text | [WebGPT: Browser-assisted question-answering with human feedback](https://arxiv.org/abs/2112.09332) | 12/21 |

## Datasets (WIP)
